# Architect Highly Available Stateful Platform on Kubernetes

## Project Overview

This project demonstrates a production-grade Highly Available platform deployed on Kubernetes.

The system consists of:

- Stateless Web Application (3 replicas)
- PostgreSQL StatefulSet (1 Primary + 2 Standbys)
- Streaming Replication
- Persistent Storage using PVCs
- PodDisruptionBudgets
- Rolling Updates (Zero Downtime)
- Automated Daily Backups using CronJob

The platform ensures business continuity during failures and traffic spikes.

---

# Architecture Overview

Users  
â”‚  
â–¼  
Web Service (NodePort)  
â”‚  
â–¼  
Web Deployment (3 replicas + anti-affinity)  
â”‚  
â–¼  
PostgreSQL Headless Service  
â”‚  
â–¼  
postgres-0 (Primary)  
postgres-1 (Standby)  
postgres-2 (Standby)  
â”‚  
â–¼  
Persistent Volume Claims (1Gi each)  
â”‚  
â–¼  
Backup CronJob (pg_dump daily)

---

# Prerequisites

Ensure the following tools are installed:

- Docker Desktop (or Kind / Minikube)
- kubectl
- Git

Verify Kubernetes is running:

```bash
kubectl cluster-info
```

---

# Project Structure

```
ha-platform-kub/
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app.js
â”‚   â”œâ”€â”€ package.json
â”‚
â””â”€â”€ k8s/
    â”œâ”€â”€ namespace.yaml
    â”œâ”€â”€ postgres-service.yaml
    â”œâ”€â”€ postgres-statefulset.yaml
    â”œâ”€â”€ postgres-pdb.yaml
    â”œâ”€â”€ web-deployment.yaml
    â”œâ”€â”€ web-service.yaml
    â”œâ”€â”€ web-pdb.yaml
    â”œâ”€â”€ backup-cronjob.yaml
```

---

# Step-by-Step Deployment Guide

## Step 1: Create Namespace

```bash
kubectl apply -f k8s/namespace.yaml
kubectl get namespaces
```

---

## Step 2: Deploy PostgreSQL StatefulSet

```bash
kubectl apply -f k8s/postgres-service.yaml
kubectl apply -f k8s/postgres-statefulset.yaml
kubectl apply -f k8s/postgres-pdb.yaml
```

Verify:

```bash
kubectl get pods -n ha-platform
kubectl get statefulset -n ha-platform
kubectl get pvc -n ha-platform
```

Expected:
- postgres-0 Running
- postgres-1 Running
- postgres-2 Running
- PVCs Bound (1Gi each)

---

## Step 3: Enable Streaming Replication (One-Time Setup)

Allow replication connections:

```bash
kubectl exec -it postgres-0 -n ha-platform -- bash
echo "host replication postgres 0.0.0.0/0 md5" >> /var/lib/postgiesql/data/pg_hba.conf
exit
kubectl delete pod postgres-0 -n ha-platform
```

Verify replication:

```bash
kubectl exec -it postgres-0 -n ha-platform -- \
psql -U postgres -c "SELECT client_addr,state FROM pg_stat_replication;"
```

Expected:
Two rows with state = streaming.

Check replica mode:

```bash
kubectl exec -it postgres-1 -n ha-platform -- \
psql -U postgres -c "SELECT pg_is_in_recovery();"
```

Expected output:
t

---

## Step 4: Deploy Web Application

```bash
kubectl apply -f k8s/web-deployment.yaml
kubectl apply -f k8s/web-service.yaml
kubectl apply -f k8s/web-pdb.yaml
```

Verify:

```bash
kubectl get pods -n ha-platform
kubectl get deployment -n ha-platform
```

Expected:
3 web pods Running.

---

## Step 5: Deploy Backup CronJob

```bash
kubectl apply -f k8s/backup-cronjob.yaml
```

Verify:

```bash
kubectl get cronjob -n ha-platform
```

Test manually:

```bash
kubectl create job --from=cronjob/postgres-backup manual-backup -n ha-platform
kubectl get jobs -n ha-platform
```

Expected:
manual-backup Complete 1/1

---

#  Verification Screenshots

## ðŸ”¹ Cluster Setup
![Cluster Nodes](screenshots/1-cluster-nodes.png)

## ðŸ”¹ High Availability (Pod Distribution)
![Pod Distribution](screenshots/2-pods-node-distribution.png)

## ðŸ”¹ PostgreSQL Streaming Replication
![Streaming Replication](screenshots/3-postgres-streaming-replication.png)

## ðŸ”¹ Persistent Storage
![PVC Bound](screenshots/4-pvc-bound.png)

## ðŸ”¹ Pod Disruption Budget
![Web PDB](screenshots/6-web-pdb.png)

## ðŸ”¹ Backup CronJob
![Backup CronJob](screenshots/7-backup-cronjob.png)

## ðŸ”¹ Manual Backup Success
![Backup Success](screenshots/8-backup-manual-success.png)

## ðŸ”¹ Application Running
![Application Running](screenshots/8-application-running.png)

## ðŸ”¹ Health Endpoint
![Health Endpoint](screenshots/9-health-endpoint.png)

## ðŸ”¹ Node Drain Eviction
![Node Drain](screenshots/10-node-drain-eviction.png)

## ðŸ”¹ Post Drain Rescheduling
![Rescheduled Pods](screenshots/11-post-drain-rescheduling.png)
---

# Resilience Testing

Simulate node disruption:

```bash
kubectl drain <node-name> --ignore-daemonsets --delete-emptydir-data
```

Observe:
- Pods rescheduled automatically
- Replication maintained
- No data loss

Re-enable node:

```bash
kubectl uncordon <node-name>
```

---

# Docker Compose Verification

To verify application logic independently:

```bash
docker-compose up --build
```

This ensures:
- Web connects to database
- Schema initializes
- Application serves traffic

---

# Production Features Implemented

- StatefulSet for PostgreSQL
- VolumeClaimTemplates (1Gi per replica)
- Streaming Replication
- PodDisruptionBudgets
- Rolling Updates
- Liveness & Readiness Probes
- Pod Anti-Affinity
- Automated Backups via CronJob
- Persistent Storage

---

# Expected Outcomes Achieved

- Database redundancy (1 Primary + 2 Standbys)
- Zero downtime deployments
- Data persistence across restarts
- Automatic failover recovery
- Scheduled daily backups

---

# Conclusion

This project demonstrates the design and deployment of a highly available, production-grade stateful platform on Kubernetes using best practices for:

- Reliability
- Data durability
- High availability
- Disaster recovery

The system successfully maintains business continuity under failure scenarios.

---

# Author

Name: Lahari Sri  
Project: Architect Highly Available Stateful Platform on Kubernetes